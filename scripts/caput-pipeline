#!/usr/bin/env python
"""Executes a data analysis pipeline given a pipeline YAML file.

This script, when executed on the command line, accepts a single parameter, the
path to a yaml pipeline file.  For an example of a pipeline file, see
documentation for caput.pipeline.
"""

from argh import arg, dispatch_commands


products = None


@arg('configfile', help='Configuration file to run.')
@arg('--loglevel', help='Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)')
def run(configfile, loglevel='INFO'):
    from caput.pipeline import Manager
    import logging
    level = getattr(logging, loglevel.upper())
    logging.basicConfig(level=level)

    P = Manager.from_yaml_file(configfile)
    P.run()


@arg('configfile', help='Configuration file to queue up.')
@arg('--nosubmit', help='Don\'t submit the job to the queue.')
def queue(configfile, nosubmit=False):

    import os.path
    import shutil
    import yaml

    with open(configfile, 'r') as f:
        yconf = yaml.safe_load(f)

    ## Global configuration
    ## Create output directory and copy over params file.
    if 'cluster' not in yconf:
        raise Exception('Configuration file must have an \'config\' section.')

    conf = yconf['cluster']

    if 'directory' not in conf:
        raise Exception('Must specify output directory.')
    workdir = conf['directory']
    workdir = os.path.normpath(os.path.expandvars(os.path.expanduser(workdir)))

    if not os.path.isabs(workdir):
        raise Exception('Output directory path must be absolute.')

    pbsdir = os.path.normpath(workdir + '/pbs/')

    # Create directory if required
    if not os.path.exists(pbsdir):
        os.makedirs(pbsdir)

    # Copy config file into output directory (check it's not already there first)
    sfile = os.path.realpath(os.path.abspath(configfile))
    dfile = os.path.realpath(os.path.abspath(pbsdir + '/config.yaml'))

    if sfile != dfile:
        shutil.copy(sfile, dfile)

    clusterconf = {}

    # Set up required PBS vars
    if 'nodes' not in conf:
        raise Exception('Nodes is required.')
    clusterconf['nodes'] = conf['nodes']

    if 'time' not in conf:
        raise Exception('Job time is required.')
    clusterconf['time'] = conf['time']

    # Set queueing system w. per-cluster defaults
    cluster_defaults = {
        'gpc' : {'ppn': 8, 'mem': '16000M', 'queue_sys': 'pbs', 'account':None,},
        'cedar': {'ppn': 32, 'mem': '0', 'queue_sys': 'slurm', 'account':'rpp-krs',}
    }
    if 'system' in conf:
        clusterconf['queue_sys'] = conf['queue_sys'] if 'queue_sys' in conf else cluster_defaults[conf['system']]['queue_sys']
        clusterconf['ppn'] = conf['ppn'] if 'ppn' in conf else cluster_defaults[conf['system']]['ppn']
        clusterconf['mem'] = conf['mem'] if 'mem' in conf else cluster_defaults[conf['system']]['mem']
        clusterconf['account'] = conf['account'] if 'account' in conf else cluster_defaults[conf['system']]['account']
    else:
        if 'queue_sys' in conf:
            clusterconf['queue_sys'] = conf['queue_sys']
        else:
            clusterconf['queue_sys'] = 'pbs'
            raise Warning('Queueing system not set, defaulting to PBS')
        clusterconf['ppn'] = conf['ppn'] if 'ppn' in conf else 8
        clusterconf['mem'] = conf['mem'] if 'mem' in conf else '16000M'
        clusterconf['account'] = conf['account'] if 'account' in conf else None

    # Set up optional PBS vars
    clusterconf['ompnum'] = conf['ompnum'] if 'ompnum' in conf else 8
    clusterconf['queue'] = conf['queue'] if 'queue' in conf else 'batch'
    clusterconf['pernode'] = conf['pernode'] if 'pernode' in conf else 1
    clusterconf['name'] = conf['name'] if 'name' in conf else 'job'

    # Set vars only needed to create script
    clusterconf['mpiproc'] = clusterconf['nodes'] * clusterconf['pernode']
    clusterconf['workdir'] = workdir
    clusterconf['scriptpath'] = os.path.realpath(__file__)
    clusterconf['logpath'] = pbsdir + '/jobout.log'
    clusterconf['configpath'] = pbsdir + '/config.yaml'

    # Set up virtualenv
    if 'venv' in conf:
        if not os.path.exists(conf['venv'] + '/bin/activate'):
            raise Exception('Could not find virtualenv')

        clusterconf['venv'] = conf['venv'] + '/bin/activate'
    else:
        clusterconf['venv'] = '/dev/null'

    pbs_script = """#!/bin/bash
#PBS -l nodes=%(nodes)i:ppn=%(ppn)i
#PBS -q %(queue)s
#PBS -r n
#PBS -m abe
#PBS -V
#PBS -l walltime=%(time)s
#PBS -N %(name)s

source %(venv)s

cd %(workdir)s
export OMP_NUM_THREADS=%(ompnum)i

mpirun -np %(mpiproc)i -npernode %(pernode)i -bind-to none python %(scriptpath)s run %(configpath)s &> %(logpath)s
"""
    slurm_script = """#!/bin/bash
#SBATCH --account=%(account)s
#SBATCH --nodes=%(nodes)i
#SBATCH --ntasks-per-node=%(pernode)i # number of MPI processes
#SBATCH --cpus-per-task=%(ompnum)i # number of OpenMP processes
#SBATCH --mem=%(mem)s # memory per node
#SBATCH --time=%(time)s
#SBATCH --job-name=%(name)s

source %(venv)s

cd %(workdir)s
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

mpirun -np %(mpiproc)i -npernode %(pernode)i -bind-to none python %(scriptpath)s run %(configpath)s &> %(logpath)s
"""

    if clusterconf['queue_sys'] == 'pbs':
        script = pbs_script % clusterconf
        job_command = 'qsub'
    elif clusterconf['queue_sys'] == 'slurm':
        script = slurm_script % clusterconf
        job_command = 'sbatch'
    else:
        raise Exception('Specified queueing system not recognized')

    scriptname = pbsdir + '/jobscript.sh'

    with open(scriptname, 'w') as f:
        f.write(script)

    if not nosubmit:
        os.system('cd %s; %s jobscript.sh' % (pbsdir, job_command))


if __name__ == '__main__':
    dispatch_commands([run, queue])
